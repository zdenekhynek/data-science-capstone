{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MONGODB_URI=mongodb://localhost:27017/\n"
     ]
    }
   ],
   "source": [
    "%env MONGODB_URI=mongodb://localhost:27017/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import ward, dendrogram\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from articles import articles\n",
    "from tokenizer.tokenize_and_stem import tokenize_and_stem\n",
    "from tokenizer.remove_html import remove_html\n",
    "from vectorization import tf_idf\n",
    "from performance.benchmarks import Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_pipeline(parameters={}):\n",
    "    benchmarks = Benchmarks()\n",
    "\n",
    "    ####################################################\n",
    "    # 1. get the documents a process them\n",
    "    ####################################################\n",
    "\n",
    "    doc_params = parameters['documents']\n",
    "    documents = articles.get_articles(doc_params['query']).limit(doc_params['limit'])\n",
    "    article_docs = [document for document in documents]\n",
    "    benchmarks.add_benchmark('1-get-articles')\n",
    "\n",
    "    # 1a. get just body documents\n",
    "    texts = articles.get_document_texts(article_docs)\n",
    "    titles = articles.get_document_titles(article_docs)\n",
    "    benchmarks.add_benchmark('2-get-body-documents')\n",
    "\n",
    "    # 1b. remove html\n",
    "    texts = [remove_html(text) for text in texts]\n",
    "    benchmarks.add_benchmark('3-remove-html')\n",
    "\n",
    "    ####################################################\n",
    "    # 2. tf_idf\n",
    "    ####################################################\n",
    "\n",
    "    vectorizer, matrix = tf_idf.fit_texts(texts, tokenize_and_stem,\n",
    "                                          parameters['tf_idf'])\n",
    "    benchmarks.add_benchmark('4-tf-idf')\n",
    "\n",
    "    ####################################################\n",
    "    # 3. hierarchical clustering\n",
    "    # ####################################################\n",
    "\n",
    "    dist = 1 - cosine_similarity(matrix)\n",
    "\n",
    "    linkage_matrix = ward(dist)  # define the linkage_matrix using ward clustering pre-computed distances\n",
    "    benchmarks.add_benchmark('5-hiearchical-clustering')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 20))  # set size\n",
    "    ax = dendrogram(linkage_matrix, orientation=\"right\", labels=titles)\n",
    "\n",
    "    plt.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off')\n",
    "\n",
    "    plt.tight_layout()  # show plot with tight layout\n",
    "\n",
    "    benchmarks.add_benchmark('6-displaying-result')\n",
    "\n",
    "    # uncomment below to save figure\n",
    "    plt.savefig('data/ward_clusters.png', dpi=300)  # save figure as ward_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1-get-articles', 'time': 0.002642000000000033}\n",
      "{'id': '2-get-body-documents', 'time': 0.00011300000000002974}\n",
      "{'id': '3-remove-html', 'time': 0.02399600000000013}\n",
      "{'id': '4-tf-idf', 'time': 0.2814030000000003}\n",
      "{'id': '5-hiearchical-clustering', 'time': 0.0021100000000000563}\n",
      "{'id': '6-displaying-result', 'time': 0.15028799999999976}\n"
     ]
    }
   ],
   "source": [
    "news_only_query = {'$or': [{'sectionId': 'world'}, {'sectionId': 'uk-news'}]}\n",
    "\n",
    "parameters = {\n",
    "    'documents': {\n",
    "        'query': news_only_query,\n",
    "        'limit': 10\n",
    "    },\n",
    "    'tf_idf': {\n",
    "        'ngram_range': (1, 2),\n",
    "        'min_df': 2,\n",
    "        'max_df': 1.0,\n",
    "        'max_features': None\n",
    "    },\n",
    "    'lda': {\n",
    "        'num_topics': 20,\n",
    "        'no_below': 1,\n",
    "        'no_above': 0.8,\n",
    "        'update_every': 5,\n",
    "        'chunksize': 10000,\n",
    "        'passes': 100\n",
    "    }\n",
    "}\n",
    "\n",
    "run_pipeline(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
